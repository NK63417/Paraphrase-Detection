# Paraphrase Detection using Transformers and Graphs

An NLP model that combines BERT with Graph Attention Networks (GAT) to detect paraphrased sentence pairs from the MRPC dataset.

---

## ğŸš€ Project Highlights

- Combines **transformer-based contextual modeling** with **graph-based token interaction**
- Achieved **F1-score of 0.873** on the MRPC dataset
- Built using **TensorFlow**, **BERT (bert-base-uncased)**, and **custom GAT layers**
- Compared against baseline BERT-only model

---

## ğŸ§  Methodology

- **Input**: Sentence pairs from MRPC
- **Backbone**: BERT extracts contextual embeddings
- **Graph Attention**: Learns semantic relationships between token embeddings
- **Output**: Binary classification â€“ paraphrase or not

---

## ğŸ“Š Results

| Metric        | Hybrid Model | Base BERT |
|---------------|--------------|------------|
| Accuracy      | 0.8145       | 0.664      |
| Precision     | 0.798        | 0.664      |
| Recall        | 0.965        | 1.0        |
| F1 Score      | 0.873        | 0.798      |

---

## ğŸ“ File Structure

Paraphrase-Detection/
â”œâ”€â”€ report/             # Final PDF paper
â”œâ”€â”€ presentation/       # PPT slides
â”œâ”€â”€ notebooks/          # Model development notebooks (if public)
â”œâ”€â”€ src/                # Custom code (e.g., GAT layers)
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE

---

## âš™ï¸ Installation

```bash
git clone https://github.com/NK63417/Paraphrase-Detection.git
cd Paraphrase-Detection
pip install -r requirements.txt
```

---

ğŸ§ª Run the Model

```python
python train_model.py
```

---

ğŸ“š References
  â€¢	GLUE Benchmark
	â€¢	BERT: Devlin et al. (2018)
	â€¢	GAT: Velickovic et al. (2017)

 ---

 ğŸ™‹â€â™‚ï¸ About Me

Nanda Kishore Kappaganthula
Graduate, Computer Science â€“ Western University
Reach me at: nandakishore02aug@gmail.com

---
